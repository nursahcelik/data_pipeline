{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afcf201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de4a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract website data from the soup object\n",
    "def get_website(soup):\n",
    "  # Find the element with class 'infobox-label' and text 'Website'\n",
    "  website_elem = soup.find(class_=\"infobox-label\", string=\"Website\")\n",
    "  if website_elem:\n",
    "    # If found, return the next sibling element with class 'infobox-data'\n",
    "    next_elem = website_elem.find_next(class_='infobox-data')\n",
    "    return next_elem.text\n",
    "  else:\n",
    "      # If not found, return None\n",
    "      return None\n",
    "\n",
    "# Function to extract population data from the soup object\n",
    "def get_population(soup):\n",
    "    # Find the table header element containing the text 'Population'\n",
    "    population_elem = soup.select_one('th.infobox-header:-soup-contains(\"Population\")')\n",
    "    # If found, find the next sibling and extract the first numerical data\n",
    "    return population_elem.parent.find_next_sibling().find(string=re.compile(r'\\d+')) if population_elem else None # note the different syntax for the if/else clause here\n",
    "\n",
    "# Function to clean the data in the DataFrame\n",
    "def clean_data(df):\n",
    "    # Remove unnecessary characters from 'latitude' and 'longitude' columns\n",
    "    df['latitude'] = df['latitude'].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False)\n",
    "    df['longitude'] = df['longitude'].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False)\n",
    "\n",
    "# Function to extract city info from its Wikipedia page\n",
    "def get_city_info(city):\n",
    "    # Construct the URL\n",
    "    url = f'https://en.wikipedia.org/wiki/{city}'\n",
    "    # Send a GET request\n",
    "    r = requests.get(url)\n",
    "    # Parse the response content with BeautifulSoup\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        # Construct a dictionary with necessary details\n",
    "        response_dict = {\n",
    "            'city': soup.select_one(\".firstHeading\").get_text(),\n",
    "            'country': soup.select_one(\".infobox-data\").get_text(),\n",
    "            'latitude': soup.select_one(\".latitude\").get_text(),\n",
    "            'longitude': soup.select_one(\".longitude\").get_text(),\n",
    "            'website': get_website(soup),\n",
    "            'population': get_population(soup)\n",
    "        }\n",
    "    except AttributeError:\n",
    "        # If any data is missing, print an error message and return None\n",
    "        print(f'Failed to get data for {city}')\n",
    "        return None\n",
    "\n",
    "    return response_dict\n",
    "\n",
    "# Function to scrape data for a list of cities and return a DataFrame\n",
    "def recreate_wiki(cities):\n",
    "    # Get info for each city\n",
    "    city_data = [get_city_info(city) for city in cities]\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    cities_df = pd.DataFrame(city_data)\n",
    "    # Clean the data\n",
    "    clean_data(cities_df)\n",
    "    # Return the DataFrame\n",
    "    return cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d219b9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>website</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>52.3112</td>\n",
       "      <td>13.2418</td>\n",
       "      <td>berlin.de</td>\n",
       "      <td>3,850,809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>53.33N</td>\n",
       "      <td>10.00E</td>\n",
       "      <td>hamburg.com</td>\n",
       "      <td>1,906,411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>53.5N</td>\n",
       "      <td>8.48E</td>\n",
       "      <td>Bremen online</td>\n",
       "      <td>563,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>Germany</td>\n",
       "      <td>48.0815</td>\n",
       "      <td>11.3430</td>\n",
       "      <td>stadt.muenchen.de</td>\n",
       "      <td>1,512,491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Germany</td>\n",
       "      <td>48.4639</td>\n",
       "      <td>09.1048</td>\n",
       "      <td>www.stuttgart-tourist.de</td>\n",
       "      <td>626,275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  country latitude longitude                    website population\n",
       "0     Berlin  Germany  52.3112   13.2418                  berlin.de  3,850,809\n",
       "1    Hamburg  Germany   53.33N    10.00E                hamburg.com  1,906,411\n",
       "2     Bremen  Germany    53.5N     8.48E              Bremen online    563,290\n",
       "3     Munich  Germany  48.0815   11.3430          stadt.muenchen.de  1,512,491\n",
       "4  Stuttgart  Germany  48.4639   09.1048  www.stuttgart-tourist.de     626,275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cities = ['Berlin', 'Hamburg', 'Bremen', 'Munich', 'Stuttgart']\n",
    "recreate_wiki(list_of_cities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
